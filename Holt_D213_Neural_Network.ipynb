{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Research Question\n",
    "## A1: Research Question\n",
    "\n",
    "Can we predict customers' opinion of a product using a 5-star system (1 star being most negative, 5 stars being most positive), using written reviews from previous customers?\n",
    "\n",
    "## A2: Objective and Goal of Data Analysis\n",
    "\n",
    "The goal of the data analysis is to attempt to accurately identify what words and words patterns are strongly associated with each rating of the 5-star system. This will allow product developers to better understand the needs and wants of their customers to decide what features to add, retain, or remove from future products.  \n",
    "\n",
    "## A3: Neural Network Identification\n",
    "\n",
    "A type of neural network capable of performing a text classification task is a Recurrent Neural Network(RNN). RNN works by taking sequential data (in this case a written review) and running each piece of the input (each word of the review) through the model. The input loops through each layer of the model with each piece as the input while taking into account the previous inputs already ran through it. RRN works great for text data because the sequence of the data matters when creating output predictions.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Data Preparation\n",
    "## B1: Exploratory Data Analysis \n",
    "This section describes the process used for initial data cleaning and preprocessing. The process includes addressing the presence of unusual characters, vocabulary size, word embedding length, and the statistical justification for the chosen maximum sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used throughout the task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as ks\n",
    "import tensorflow as tf\n",
    "import spacy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding, Dense, Dropout, GlobalMaxPool1D\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "This script imports the video game review .json file and transforms each portion of the .json into DataFrame columns. The script was borrowed and adjusted from J. McAuley's site at jmcauley.ucsd.edu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to import and tranform json formatted data into dataframe\n",
    "def parse(path):\n",
    "  g = gzip.open(\"C:/Users/holtb/Documents/GitHub/D213_Advanced_Data_Analytics/reviews_Video_Games_5.json.gz\", 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of data\n",
    "In this section, the data was reviewed for length, data types, duplicates, and missing data. Since the model will focus on only the review text as the input and the overall rating, the unused columns were dropped. The data was then checked for duplicate results. There were only 86 duplicates and were found to be one or two-letter reviews. These duplicates will remain in the data since there are relatively few duplicates. A few blank reviews were also found and were removed as they provide no information. Finally, the column, 'overall' was transformed to integer values because they are categorical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231780 entries, 0 to 231779\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   reviewerID      231780 non-null  object \n",
      " 1   asin            231780 non-null  object \n",
      " 2   reviewerName    228967 non-null  object \n",
      " 3   helpful         231780 non-null  object \n",
      " 4   reviewText      231780 non-null  object \n",
      " 5   overall         231780 non-null  float64\n",
      " 6   summary         231780 non-null  object \n",
      " 7   unixReviewTime  231780 non-null  int64  \n",
      " 8   reviewTime      231780 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 17.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Review initial data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "data = df.drop(df[['reviewerID', 'reviewerName' ,'asin', 'helpful', 'summary', 'unixReviewTime', 'reviewTime' ]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  Installing the game was a struggle (because of...      1.0\n",
       "1  If you like rally cars get this game you will ...      4.0\n",
       "2  1st shipment received a book instead of the ga...      1.0\n",
       "3  I got this version instead of the PS3 version,...      3.0\n",
       "4  I had Dirt 2 on Xbox 360 and it was an okay ga...      4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review data after dropping features\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            reviewText  overall\n",
      "377        Great game!      5.0\n",
      "5397        great game      4.0\n",
      "6846           love it      5.0\n",
      "16824   best game ever      5.0\n",
      "24299                       5.0\n",
      "...                ...      ...\n",
      "227378           Works      5.0\n",
      "229524           Great      5.0\n",
      "229887   Awesome game.      5.0\n",
      "230623           great      5.0\n",
      "230692       Good game      5.0\n",
      "\n",
      "[126 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify abnormal duplicates\n",
    "duplicates = data[data.duplicated(keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "# Identify number of duplicated entries\n",
    "duplicates = data.duplicated().astype(int).sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blank entries with NaN\n",
    "data = data.replace(r\"^\\s*$\",np.nan,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    44\n",
       "overall        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of blank entries\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blank entries\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change overall feature datatype to int\n",
    "data['overall'] = data['overall'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review and remove unusual characters and text\n",
    "\n",
    "After performing code to return an initial list of characters in the dataset it revealed that there were many characters and punctuation in the data that would make effective tokenization difficult and/or are not useful for the objective of the analysis. Additionally, some URLs were found in the data set that will be removed. \n",
    "\n",
    "Although filtering specified characters can be conducted through some tokenizers, a manual code was written to remove all these characters as well as any URL text within the data set. After running the code, specific and random rows were checked to ensure expected results were obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'n', 's', 't', 'a', 'l', 'i', 'g', ' ', 'h', 'e', 'm', 'w', 'r', 'u', '(', 'b', 'c', 'o', 'f', 'd', 'v', ')', '.', 'S', 'p', 'y', '\"', 'k', '3', '0', \"'\", 'D', '2', '/', 'x', 'R', 'B', ',', ':', 'z', '-', 'P', 'C', '9', '7', '1', '5', '6', '=', '_', '?', 'U', 'T', 'F', '8', '&', 'q', ';', '4', '+', '!', 'j', '#', 'E', 'A', 'M', 'K', 'G', 'V', 'N', 'W', 'L', 'X', 'O', '*', 'Y', 'H', 'J', 'Z', '>', '%', '$', '^', '[', ']', 'Q', '@', '{', '}', '|', '`', '~', '\\\\', '\\x19', '\\x1c', '\\x1d', '\\x10', '\\x1b']\n"
     ]
    }
   ],
   "source": [
    "first_review = data['reviewText']\n",
    "first_list_of_characters = []\n",
    "for review in first_review:\n",
    "    for ch in review:\n",
    "        if ch not in first_list_of_characters:\n",
    "            first_list_of_characters.append(ch)\n",
    "            \n",
    "print(first_list_of_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that cleans each string\n",
    "def clean_text(string):\n",
    "    # Strip left and right whitespace\n",
    "    stripped = string.strip()\n",
    "    # Remove urls\n",
    "    no_url = re.sub(r'http\\S+', ' ', stripped)\n",
    "    # Replace basicpunctuation with spaces\n",
    "    no_punc = re.sub(r'[.!?]', ' ', no_url)\n",
    "    # Replace spaces with '_'\n",
    "    mark_spaces = re.sub(' ', '_', no_punc)\n",
    "    # Remove all non-alpha numeric chars\n",
    "    no_uchars = re.sub(r\"[^a-zA-Z\\d_']+\", \" \", mark_spaces)\n",
    "    # Reapply replace spaces with '_'\n",
    "    remark_spaces = re.sub(' ', '_', no_punc) \n",
    "    # Replace all '_' with spaces\n",
    "    cleaned_text = re.sub(r'_+', \" \", no_uchars) \n",
    "    \n",
    "    # return cleaned resluts and lowercase all words\n",
    "    return cleaned_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the data\n",
    "data['reviewText'] = data['reviewText'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"installing the game was a struggle  because of games for windows live bugs  some championship races and cars can only be  unlocked  by buying them as an addon to the game i paid nearly 30 dollars when the game was new i don't like the idea that i have to keep paying to keep playing i noticed no improvement in the physics or graphics compared to dirt 2 i tossed it in the garbage and vowed never to buy another codemasters game i'm really tired of arcade style rally racing games anyway i'll continue to get my fix from richard burns rally  and you should to   you for reading my review if you enjoyed it  be sure to rate it as helpful \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first row for correctness (contained a URL)\n",
    "data['reviewText'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use specified  34 gestures 34  to play this game and feel like a mighty  34 powerup hero 34  as you pull off powers and combos that make anyone watching say  34 dag  34  you can collect powers from the characters you beat and bonuses as you level up this and kung fu high impact get my  34 highly recommended 34  rating '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use np random function to check a random reviewText for correct output\n",
    "data['reviewText'].iloc[np.random.randint(231736)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', \"'\", '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "second_review = data['reviewText']\n",
    "second_list_of_characters = []\n",
    "for review in second_review:\n",
    "    for ch in review:\n",
    "        if ch not in second_list_of_characters:\n",
    "            second_list_of_characters.append(ch)\n",
    "            \n",
    "print(sorted(second_list_of_characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Statistical analysis was performed to find the number of characters, number of words, the average length of words, and maximum word length for each row. Additionally, the median word length and character length for the entire data set were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of characters in each row\n",
    "data['num_chars'] = data['reviewText'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of words in each row\n",
    "def word_count(string):\n",
    "    # Split the string into words\n",
    "    words = string.split()\n",
    "    \n",
    "    # Return length of words list\n",
    "    return len(words)\n",
    "\n",
    "# Create num_words feature in df\n",
    "data['num_words'] = data['reviewText'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns average word length\n",
    "def average_word_length(x):\n",
    "    # Split the string into words\n",
    "    words = x.split()\n",
    "    # Compute length of each word and store in a sepatate list\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    # Compute average word length\n",
    "    avg_word_length = sum(word_lengths)/len(words) if len(words) > 0 else 1\n",
    "    # Return average word length\n",
    "    return(avg_word_length)\n",
    "\n",
    "data['avg_word_length'] = data['reviewText'].apply(average_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns average word length\n",
    "def max_word_length(x):\n",
    "    # Split the string into words\n",
    "    words = x.split()\n",
    "    # Compute length of each word and store in a separate list\n",
    "    word_length = [len(word) for word in words]\n",
    "    # Compute max word length\n",
    "    max_word_length = max(word_length, default=1)\n",
    "    # Return average word length\n",
    "    return(max_word_length)\n",
    "\n",
    "data['max_word_length'] = data['reviewText'].apply(max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['median_word_length'] = data['num_words'].median() \n",
    "data['median_char_length'] = data['num_chars'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>max_word_length</th>\n",
       "      <th>median_word_length</th>\n",
       "      <th>median_char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171221</th>\n",
       "      <td>for those that haven't finished mass effect 3 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>32500</td>\n",
       "      <td>5861</td>\n",
       "      <td>4.479099</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187149</th>\n",
       "      <td>this is the same review as the one i posted fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>32492</td>\n",
       "      <td>5872</td>\n",
       "      <td>4.467984</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163174</th>\n",
       "      <td>the witcher 2  assassin of kings  is from the...</td>\n",
       "      <td>5</td>\n",
       "      <td>32188</td>\n",
       "      <td>5732</td>\n",
       "      <td>4.540998</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167783</th>\n",
       "      <td>dragon age  origins ultimate edition1 origins2...</td>\n",
       "      <td>5</td>\n",
       "      <td>32075</td>\n",
       "      <td>5585</td>\n",
       "      <td>4.670009</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130797</th>\n",
       "      <td>first of all  i have something important to sh...</td>\n",
       "      <td>4</td>\n",
       "      <td>32017</td>\n",
       "      <td>5764</td>\n",
       "      <td>4.487335</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130369</th>\n",
       "      <td>super mario galaxy 2 is  unfortunately  unforg...</td>\n",
       "      <td>3</td>\n",
       "      <td>31534</td>\n",
       "      <td>5528</td>\n",
       "      <td>4.651049</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151392</th>\n",
       "      <td>so here is the deal i am reviewing the game  n...</td>\n",
       "      <td>5</td>\n",
       "      <td>31511</td>\n",
       "      <td>5940</td>\n",
       "      <td>4.214310</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>shigeru miyamoto created a masterpiece when he...</td>\n",
       "      <td>5</td>\n",
       "      <td>31280</td>\n",
       "      <td>5889</td>\n",
       "      <td>4.252335</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112444</th>\n",
       "      <td>edited for brevity readability and corrected a...</td>\n",
       "      <td>1</td>\n",
       "      <td>30709</td>\n",
       "      <td>5657</td>\n",
       "      <td>4.334453</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165557</th>\n",
       "      <td>2010 was a great year for gaming it was one of...</td>\n",
       "      <td>5</td>\n",
       "      <td>30220</td>\n",
       "      <td>5205</td>\n",
       "      <td>4.702978</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall  num_chars  \\\n",
       "171221  for those that haven't finished mass effect 3 ...        2      32500   \n",
       "187149  this is the same review as the one i posted fo...        2      32492   \n",
       "163174   the witcher 2  assassin of kings  is from the...        5      32188   \n",
       "167783  dragon age  origins ultimate edition1 origins2...        5      32075   \n",
       "130797  first of all  i have something important to sh...        4      32017   \n",
       "130369  super mario galaxy 2 is  unfortunately  unforg...        3      31534   \n",
       "151392  so here is the deal i am reviewing the game  n...        5      31511   \n",
       "10683   shigeru miyamoto created a masterpiece when he...        5      31280   \n",
       "112444  edited for brevity readability and corrected a...        1      30709   \n",
       "165557  2010 was a great year for gaming it was one of...        5      30220   \n",
       "\n",
       "        num_words  avg_word_length  max_word_length  median_word_length  \\\n",
       "171221       5861         4.479099               16               109.0   \n",
       "187149       5872         4.467984               16               109.0   \n",
       "163174       5732         4.540998               15               109.0   \n",
       "167783       5585         4.670009               15               109.0   \n",
       "130797       5764         4.487335               14               109.0   \n",
       "130369       5528         4.651049               15               109.0   \n",
       "151392       5940         4.214310               15               109.0   \n",
       "10683        5889         4.252335               14               109.0   \n",
       "112444       5657         4.334453               16               109.0   \n",
       "165557       5205         4.702978               16               109.0   \n",
       "\n",
       "        median_char_length  \n",
       "171221               568.0  \n",
       "187149               568.0  \n",
       "163174               568.0  \n",
       "167783               568.0  \n",
       "130797               568.0  \n",
       "130369               568.0  \n",
       "151392               568.0  \n",
       "10683                568.0  \n",
       "112444               568.0  \n",
       "165557               568.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort dataframe by highest number of characters.\n",
    "data.sort_values(by=['num_chars'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>max_word_length</th>\n",
       "      <th>median_word_length</th>\n",
       "      <th>median_char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151392</th>\n",
       "      <td>so here is the deal i am reviewing the game  n...</td>\n",
       "      <td>5</td>\n",
       "      <td>31511</td>\n",
       "      <td>5940</td>\n",
       "      <td>4.214310</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>shigeru miyamoto created a masterpiece when he...</td>\n",
       "      <td>5</td>\n",
       "      <td>31280</td>\n",
       "      <td>5889</td>\n",
       "      <td>4.252335</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187149</th>\n",
       "      <td>this is the same review as the one i posted fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>32492</td>\n",
       "      <td>5872</td>\n",
       "      <td>4.467984</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171221</th>\n",
       "      <td>for those that haven't finished mass effect 3 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>32500</td>\n",
       "      <td>5861</td>\n",
       "      <td>4.479099</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130797</th>\n",
       "      <td>first of all  i have something important to sh...</td>\n",
       "      <td>4</td>\n",
       "      <td>32017</td>\n",
       "      <td>5764</td>\n",
       "      <td>4.487335</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163174</th>\n",
       "      <td>the witcher 2  assassin of kings  is from the...</td>\n",
       "      <td>5</td>\n",
       "      <td>32188</td>\n",
       "      <td>5732</td>\n",
       "      <td>4.540998</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112444</th>\n",
       "      <td>edited for brevity readability and corrected a...</td>\n",
       "      <td>1</td>\n",
       "      <td>30709</td>\n",
       "      <td>5657</td>\n",
       "      <td>4.334453</td>\n",
       "      <td>16</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167783</th>\n",
       "      <td>dragon age  origins ultimate edition1 origins2...</td>\n",
       "      <td>5</td>\n",
       "      <td>32075</td>\n",
       "      <td>5585</td>\n",
       "      <td>4.670009</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130369</th>\n",
       "      <td>super mario galaxy 2 is  unfortunately  unforg...</td>\n",
       "      <td>3</td>\n",
       "      <td>31534</td>\n",
       "      <td>5528</td>\n",
       "      <td>4.651049</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92896</th>\n",
       "      <td>title says it all i was excited to finally be ...</td>\n",
       "      <td>3</td>\n",
       "      <td>29605</td>\n",
       "      <td>5309</td>\n",
       "      <td>4.493125</td>\n",
       "      <td>15</td>\n",
       "      <td>109.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall  num_chars  \\\n",
       "151392  so here is the deal i am reviewing the game  n...        5      31511   \n",
       "10683   shigeru miyamoto created a masterpiece when he...        5      31280   \n",
       "187149  this is the same review as the one i posted fo...        2      32492   \n",
       "171221  for those that haven't finished mass effect 3 ...        2      32500   \n",
       "130797  first of all  i have something important to sh...        4      32017   \n",
       "163174   the witcher 2  assassin of kings  is from the...        5      32188   \n",
       "112444  edited for brevity readability and corrected a...        1      30709   \n",
       "167783  dragon age  origins ultimate edition1 origins2...        5      32075   \n",
       "130369  super mario galaxy 2 is  unfortunately  unforg...        3      31534   \n",
       "92896   title says it all i was excited to finally be ...        3      29605   \n",
       "\n",
       "        num_words  avg_word_length  max_word_length  median_word_length  \\\n",
       "151392       5940         4.214310               15               109.0   \n",
       "10683        5889         4.252335               14               109.0   \n",
       "187149       5872         4.467984               16               109.0   \n",
       "171221       5861         4.479099               16               109.0   \n",
       "130797       5764         4.487335               14               109.0   \n",
       "163174       5732         4.540998               15               109.0   \n",
       "112444       5657         4.334453               16               109.0   \n",
       "167783       5585         4.670009               15               109.0   \n",
       "130369       5528         4.651049               15               109.0   \n",
       "92896        5309         4.493125               15               109.0   \n",
       "\n",
       "        median_char_length  \n",
       "151392               568.0  \n",
       "10683                568.0  \n",
       "187149               568.0  \n",
       "171221               568.0  \n",
       "130797               568.0  \n",
       "163174               568.0  \n",
       "112444               568.0  \n",
       "167783               568.0  \n",
       "130369               568.0  \n",
       "92896                568.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort dataframe by highest number of words\n",
    "data.sort_values(by=['num_words'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "To keep the test data set hidden the test data is split before continuing. This mimics the process of including unseen data into the model.\n",
    "\n",
    "To achieve vocabulary size and the correct justification for the word embedding length the tokenization process was begun on the training data set. The tokenization process will be explained in the next section.\n",
    "\n",
    "The library 'spacy' and 'Keras' was used to initially preprocess the training data. This is shown below in the defined function ```preprocess```. Both tokenization and lemmatization were conducted on the data and returned those results into the X_train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate space.load() with 'en_core_web_sm' model\n",
    "nlp = sp.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of stopwords\n",
    "stopwords = sp.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess(text):\n",
    "        # Create Doc object\n",
    "        doc = nlp(text, disable=['ner', 'parser'])\n",
    "        # Generate lemmas\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        # Remove stopwords and non-alphabetic characters\n",
    "        a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stopwords]\n",
    "    \n",
    "        return ' '.join(a_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocess to data['reviewText']\n",
    "data['reviewText'] = data['reviewText'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['X'] = data['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(data['overall'])\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data['X'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dictionary of indexes\n",
    "tokenizer = Tokenizer(oov_token='UNK')\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our data's word index\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 1,\n",
       " 'i': 2,\n",
       " 'game': 3,\n",
       " 'play': 4,\n",
       " 'like': 5,\n",
       " 'good': 6,\n",
       " 'time': 7,\n",
       " 'great': 8,\n",
       " 'fun': 9,\n",
       " 'use': 10,\n",
       " 'character': 11,\n",
       " 'new': 12,\n",
       " 'thing': 13,\n",
       " 'graphic': 14,\n",
       " 'look': 15,\n",
       " 'buy': 16,\n",
       " 'story': 17,\n",
       " 'level': 18,\n",
       " 'find': 19,\n",
       " 'way': 20}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output first 20 results of work_index dictionary\n",
    "dict(list(word_index.items())[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size\n",
    "\n",
    "After the preprocessing and tokenization process was completed on the training data, the vocabulary size was calculated. The initial code blocks calculate the number of times a unique word occurs in the training data set. The actual vocabulary size is calculated by performing the ```len()``` function on the word_index that was created from the training data above. The total size of the vocabulary is 147,781 words.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = X_train.str.split(expand=True).stack().value_counts().reset_index()\n",
    " \n",
    "word_count.columns = ['Word', 'Frequency'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>904410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game</td>\n",
       "      <td>803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>play</td>\n",
       "      <td>245094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>195637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>150889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>132982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great</td>\n",
       "      <td>103220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fun</td>\n",
       "      <td>97414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>use</td>\n",
       "      <td>95432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>character</td>\n",
       "      <td>82277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Frequency\n",
       "0          I     904410\n",
       "1       game     803571\n",
       "2       play     245094\n",
       "3       like     195637\n",
       "4       good     150889\n",
       "5       time     132982\n",
       "6      great     103220\n",
       "7        fun      97414\n",
       "8        use      95432\n",
       "9  character      82277"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return top ten most common words\n",
    "word_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147781\n"
     ]
    }
   ],
   "source": [
    "# Create the length of the vocabulary\n",
    "vocabulary_size = len(word_index)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding length\n",
    "\n",
    "Now that the vocabulary_size is calculated we can propose a word embedding length. The word embedding length will be an input in the output dimension parameter of the ```keras.Embedding``` layer of the model. During the research, there were many \"rules of thumbs\" found to determine the word embedding length. One was to use the 4th root of the vocabulary length (about 20 in our case). (Introducing tensorflow feature columns, 2017) Another source stated that multiples of 32 should be used. Yet another source stated that literature shows that a word embedding length of 300 is the most common. (Yin & Shin) Since these are just rules of thumb, each can be tried to see which provides the most accurate results. For simplicity's sake, the first word embedding length was selected was between the suggested numbers: 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical justification for maximum sequence length\n",
    "\n",
    "The maximum sequence length to be used in the model input is 200. This is statistically justified by plotting a histogram using matplotlib and evaluating the outcome. As shown below, well over 99% of the data contains 200 or fewer words. Using 200 as the max length will contain enough information to build an acceptable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37956</th>\n",
       "      <td>game pretty fun evil crocidle imagine stand be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127119</th>\n",
       "      <td>like need speed game want try like kid great g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157359</th>\n",
       "      <td>problem game replay value beat game yes I play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198517</th>\n",
       "      <td>work crack plastic I big deal wire shot normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167596</th>\n",
       "      <td>I play grand theft auto iv pc love control eas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        X\n",
       "37956   game pretty fun evil crocidle imagine stand be...\n",
       "127119  like need speed game want try like kid great g...\n",
       "157359  problem game replay value beat game yes I play...\n",
       "198517  work crack plastic I big deal wire shot normal...\n",
       "167596  I play grand theft auto iv pc love control eas..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 words:          4\n",
      "1 words:         99\n",
      "10 words:      4194\n",
      "100 words:      490\n",
      "1002 words:       1\n",
      "               ... \n",
      "991 words:        2\n",
      "992 words:        1\n",
      "994 words:        1\n",
      "995 words:        1\n",
      "998 words:        1\n",
      "Name: X, Length: 1184, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = X_train_df['X'].str.split().apply(len).value_counts()\n",
    "count.index = count.index.astype(str) + ' words:'\n",
    "count.sort_index(inplace=True)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAFlCAYAAAA+rfQNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdIklEQVR4nO3df8zlVX4X8PdHpkW2DVtYZlc6Qxx0qRWIpmVk0UazFl0w2xT+WJLZuDJRkokE+8OoFWoiSRuSRRtREiEhBYHtZlmCqxAr3RJQNyYUdna3ygJFJmWFKXSZOohYs9ShH/+4Z8ydZ5+Zgec5M/PM8HolN/d7P99zDufmwPDmy/l+b3V3AACAef7IiZ4AAACcaoRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmGzTiZ7AbOecc05v27btRE8DAIBT3Ne+9rXf6+7Nq5075UL2tm3bsnv37hM9DQAATnFV9d8Pd852EQAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmGzTiZ7AqWTbjb96oqfAcfCtz37yRE8BANjgXMkGAIDJhGwAAJjsqCG7qu6pqter6psr6j9VVS9U1bNV9U+W6jdV1Z5x7oql+iVV9cw4d3tV1aifXlVfHPWnqmrbUp+dVfXieO2c8o0BAOAYezdXsu9NcuVyoar+cpKrkvyZ7r4oyS+N+oVJdiS5aPS5o6pOG93uTLIryQXjdXDM65K80d0fTXJbklvHWGcnuTnJx5JcmuTmqjprTd8SAACOo6OG7O7+SpL9K8rXJ/lsd7892rw+6lcleaC73+7ul5LsSXJpVZ2b5MzufrK7O8n9Sa5e6nPfOH4oyeXjKvcVSR7r7v3d/UaSx7Ii7AMAwEa01j3ZP5TkL47tHf+pqv7cqG9J8spSu72jtmUcr6wf0qe7DyR5M8mHjjDWd6mqXVW1u6p279u3b41fCQAA5lhryN6U5KwklyX5B0keHFefa5W2fYR61tjn0GL3Xd29vbu3b968+WhzBwCAY2qtIXtvki/1wtNJ/jDJOaN+3lK7rUleHfWtq9Sz3KeqNiX5YBbbUw43FgAAbGhrDdn/NsmPJ0lV/VCS703ye0keSbJjPDHk/CxucHy6u19L8lZVXTaueF+b5OEx1iNJDj455FNJnhj7tr+c5BNVdda44fETowYAABvaUX/xsaq+kOTjSc6pqr1ZPPHjniT3jMf6/UGSnSMYP1tVDyZ5LsmBJDd09ztjqOuzeFLJGUkeHa8kuTvJ56pqTxZXsHckSXfvr6pfTPLV0e4XunvlDZgAALDhHDVkd/enD3PqM4dpf0uSW1ap705y8Sr17yS55jBj3ZNFoAcAgJOGX3wEAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyY4asqvqnqp6vaq+ucq5v19VXVXnLNVuqqo9VfVCVV2xVL+kqp4Z526vqhr106vqi6P+VFVtW+qzs6peHK+d6/62AABwHLybK9n3JrlyZbGqzkvyV5O8vFS7MMmOJBeNPndU1Wnj9J1JdiW5YLwOjnldkje6+6NJbkty6xjr7CQ3J/lYkkuT3FxVZ723rwcAAMffUUN2d38lyf5VTt2W5OeS9FLtqiQPdPfb3f1Skj1JLq2qc5Oc2d1PdncnuT/J1Ut97hvHDyW5fFzlviLJY929v7vfSPJYVgn7AACw0axpT3ZV/WSS3+nu/7Li1JYkryx93jtqW8bxyvohfbr7QJI3k3zoCGOtNp9dVbW7qnbv27dvLV8JAACmec8hu6o+kOQfJfnHq51epdZHqK+1z6HF7ru6e3t3b9+8efNqTQAA4LhZy5XsP5nk/CT/paq+lWRrkq9X1R/L4mrzeUtttyZ5ddS3rlLPcp+q2pTkg1lsTzncWAAAsKG955Dd3c9094e7e1t3b8siDP9od/9ukkeS7BhPDDk/ixscn+7u15K8VVWXjf3W1yZ5eAz5SJKDTw75VJInxr7tLyf5RFWdNW54/MSoAQDAhrbpaA2q6gtJPp7knKram+Tm7r57tbbd/WxVPZjkuSQHktzQ3e+M09dn8aSSM5I8Ol5JcneSz1XVniyuYO8YY+2vql9M8tXR7he6e7UbMAEAYEM5asju7k8f5fy2FZ9vSXLLKu12J7l4lfp3klxzmLHvSXLP0eYIAAAbiV98BACAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmOGrKr6p6qer2qvrlU+6dV9VtV9V+r6t9U1Q8snbupqvZU1QtVdcVS/ZKqemacu72qatRPr6ovjvpTVbVtqc/OqnpxvHbO+tIAAHAsvZsr2fcmuXJF7bEkF3f3n0ny35LclCRVdWGSHUkuGn3uqKrTRp87k+xKcsF4HRzzuiRvdPdHk9yW5NYx1tlJbk7ysSSXJrm5qs56718RAACOr6OG7O7+SpL9K2q/3t0HxsffSLJ1HF+V5IHufru7X0qyJ8mlVXVukjO7+8nu7iT3J7l6qc994/ihJJePq9xXJHmsu/d39xtZBPuVYR8AADacGXuy/1aSR8fxliSvLJ3bO2pbxvHK+iF9RnB/M8mHjjDWd6mqXVW1u6p279u3b11fBgAA1mtdIbuq/lGSA0k+f7C0SrM+Qn2tfQ4tdt/V3du7e/vmzZuPPGkAADjG1hyyx42IP5Hkr48tIMniavN5S822Jnl11LeuUj+kT1VtSvLBLLanHG4sAADY0NYUsqvqyiT/MMlPdvf/WTr1SJId44kh52dxg+PT3f1akreq6rKx3/raJA8v9Tn45JBPJXlihPYvJ/lEVZ01bnj8xKgBAMCGtuloDarqC0k+nuScqtqbxRM/bkpyepLHxpP4fqO7/3Z3P1tVDyZ5LottJDd09ztjqOuzeFLJGVns4T64j/vuJJ+rqj1ZXMHekSTdvb+qfjHJV0e7X+juQ27ABACAjeioIbu7P71K+e4jtL8lyS2r1HcnuXiV+neSXHOYse5Jcs/R5ggAABuJX3wEAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyY4asqvqnqp6vaq+uVQ7u6oeq6oXx/tZS+duqqo9VfVCVV2xVL+kqp4Z526vqhr106vqi6P+VFVtW+qzc/w1XqyqndO+NQAAHEPv5kr2vUmuXFG7Mcnj3X1BksfH51TVhUl2JLlo9Lmjqk4bfe5MsivJBeN1cMzrkrzR3R9NcluSW8dYZye5OcnHklya5OblMA8AABvVUUN2d38lyf4V5auS3DeO70ty9VL9ge5+u7tfSrInyaVVdW6SM7v7ye7uJPev6HNwrIeSXD6ucl+R5LHu3t/dbyR5LN8d9gEAYMNZ657sj3T3a0ky3j886luSvLLUbu+obRnHK+uH9OnuA0neTPKhI4z1XapqV1Xtrqrd+/btW+NXAgCAOWbf+Fir1PoI9bX2ObTYfVd3b+/u7Zs3b35XEwUAgGNlrSH722MLSMb766O+N8l5S+22Jnl11LeuUj+kT1VtSvLBLLanHG4sAADY0NYash9JcvBpHzuTPLxU3zGeGHJ+Fjc4Pj22lLxVVZeN/dbXruhzcKxPJXli7Nv+cpJPVNVZ44bHT4waAABsaJuO1qCqvpDk40nOqaq9WTzx47NJHqyq65K8nOSaJOnuZ6vqwSTPJTmQ5IbufmcMdX0WTyo5I8mj45Ukdyf5XFXtyeIK9o4x1v6q+sUkXx3tfqG7V96ACQAAG85RQ3Z3f/owpy4/TPtbktyySn13kotXqX8nI6Svcu6eJPccbY4AALCR+MVHAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmGxdIbuq/m5VPVtV36yqL1TVH62qs6vqsap6cbyftdT+pqraU1UvVNUVS/VLquqZce72qqpRP72qvjjqT1XVtvXMFwAAjoc1h+yq2pLkp5Ns7+6Lk5yWZEeSG5M83t0XJHl8fE5VXTjOX5TkyiR3VNVpY7g7k+xKcsF4XTnq1yV5o7s/muS2JLeudb4AAHC8rHe7yKYkZ1TVpiQfSPJqkquS3DfO35fk6nF8VZIHuvvt7n4pyZ4kl1bVuUnO7O4nu7uT3L+iz8GxHkpy+cGr3AAAsFGtOWR39+8k+aUkLyd5Lcmb3f3rST7S3a+NNq8l+fDosiXJK0tD7B21LeN4Zf2QPt19IMmbST601jkDAMDxsJ7tImdlcaX5/CQ/mOT7quozR+qySq2PUD9Sn5Vz2VVVu6tq9759+448cQAAOMbWs13kryR5qbv3dff/TfKlJH8hybfHFpCM99dH+71JzlvqvzWL7SV7x/HK+iF9xpaUDybZv3Ii3X1Xd2/v7u2bN29ex1cCAID1W0/IfjnJZVX1gbFP+vIkzyd5JMnO0WZnkofH8SNJdownhpyfxQ2OT48tJW9V1WVjnGtX9Dk41qeSPDH2bQMAwIa1aa0du/upqnooydeTHEjyjSR3Jfn+JA9W1XVZBPFrRvtnq+rBJM+N9jd09ztjuOuT3JvkjCSPjleS3J3kc1W1J4sr2DvWOl8AADhe1hyyk6S7b05y84ry21lc1V6t/S1JblmlvjvJxavUv5MR0gEA4GThFx8BAGAyIRsAACYTsgEAYDIhGwAAJhOyAQBgMiEbAAAmE7IBAGAyIRsAACYTsgEAYDIhGwAAJhOyAQBgMiEbAAAmE7IBAGAyIRsAACYTsgEAYDIhGwAAJhOyAQBgMiEbAAAmE7IBAGAyIRsAACYTsgEAYDIhGwAAJhOyAQBgMiEbAAAmE7IBAGAyIRsAACYTsgEAYDIhGwAAJhOyAQBgsnWF7Kr6gap6qKp+q6qer6o/X1VnV9VjVfXieD9rqf1NVbWnql6oqiuW6pdU1TPj3O1VVaN+elV9cdSfqqpt65kvAAAcD+u9kv0vkvxad/9wkj+b5PkkNyZ5vLsvSPL4+JyqujDJjiQXJbkyyR1VddoY584ku5JcMF5Xjvp1Sd7o7o8muS3JreucLwAAHHNrDtlVdWaSv5Tk7iTp7j/o7v+Z5Kok941m9yW5ehxfleSB7n67u19KsifJpVV1bpIzu/vJ7u4k96/oc3Csh5JcfvAqNwAAbFTruZL9J5LsS/KvquobVfXLVfV9ST7S3a8lyXj/8Gi/JckrS/33jtqWcbyyfkif7j6Q5M0kH1rHnAEA4JhbT8jelORHk9zZ3T+S5PcztoYcxmpXoPsI9SP1OXTgql1Vtbuqdu/bt+/IswYAgGNsPSF7b5K93f3U+PxQFqH722MLSMb760vtz1vqvzXJq6O+dZX6IX2qalOSDybZv3Ii3X1Xd2/v7u2bN29ex1cCAID1W3PI7u7fTfJKVf2pUbo8yXNJHkmyc9R2Jnl4HD+SZMd4Ysj5Wdzg+PTYUvJWVV029ltfu6LPwbE+leSJsW8bAAA2rE3r7P9TST5fVd+b5LeT/M0sgvuDVXVdkpeTXJMk3f1sVT2YRRA/kOSG7n5njHN9knuTnJHk0fFKFjdVfq6q9mRxBXvHOucLAADH3LpCdnf/ZpLtq5y6/DDtb0lyyyr13UkuXqX+nYyQDgAAJwu/+AgAAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTrTtkV9VpVfWNqvp34/PZVfVYVb043s9aantTVe2pqheq6oql+iVV9cw4d3tV1aifXlVfHPWnqmrbeucLAADH2owr2T+T5Pmlzzcmeby7L0jy+PicqrowyY4kFyW5MskdVXXa6HNnkl1JLhivK0f9uiRvdPdHk9yW5NYJ8wUAgGNqXSG7qrYm+WSSX14qX5XkvnF8X5Krl+oPdPfb3f1Skj1JLq2qc5Oc2d1PdncnuX9Fn4NjPZTk8oNXuQEAYKNa75Xsf57k55L84VLtI939WpKM9w+P+pYkryy12ztqW8bxyvohfbr7QJI3k3xonXMGAIBjas0hu6p+Isnr3f21d9tllVofoX6kPivnsquqdlfV7n379r3L6QAAwLGxnivZP5bkJ6vqW0keSPLjVfUrSb49toBkvL8+2u9Nct5S/61JXh31ravUD+lTVZuSfDDJ/pUT6e67unt7d2/fvHnzOr4SAACs35pDdnff1N1bu3tbFjc0PtHdn0nySJKdo9nOJA+P40eS7BhPDDk/ixscnx5bSt6qqsvGfutrV/Q5ONanxl/ju65kAwDARrLpGIz52SQPVtV1SV5Ock2SdPezVfVgkueSHEhyQ3e/M/pcn+TeJGckeXS8kuTuJJ+rqj1ZXMHecQzmCwAAU00J2d39H5P8x3H8P5Jcfph2tyS5ZZX67iQXr1L/TkZIBwCAk4VffAQAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJhGwAAJhMyAYAgMmEbAAAmEzIBgCAyYRsAACYTMgGAIDJ1hyyq+q8qvoPVfV8VT1bVT8z6mdX1WNV9eJ4P2upz01VtaeqXqiqK5bql1TVM+Pc7VVVo356VX1x1J+qqm3r+K4AAHBcrOdK9oEkf6+7/3SSy5LcUFUXJrkxyePdfUGSx8fnjHM7klyU5Mokd1TVaWOsO5PsSnLBeF056tcleaO7P5rktiS3rmO+AABwXKw5ZHf3a9399XH8VpLnk2xJclWS+0az+5JcPY6vSvJAd7/d3S8l2ZPk0qo6N8mZ3f1kd3eS+1f0OTjWQ0kuP3iVGwAANqope7LHNo4fSfJUko9092vJIogn+fBotiXJK0vd9o7alnG8sn5In+4+kOTNJB+aMWcAADhW1h2yq+r7k/zrJD/b3f/rSE1XqfUR6kfqs3IOu6pqd1Xt3rdv39GmDAAAx9S6QnZVfU8WAfvz3f2lUf722AKS8f76qO9Nct5S961JXh31ravUD+lTVZuSfDDJ/pXz6O67unt7d2/fvHnzer4SAACs23qeLlJJ7k7yfHf/s6VTjyTZOY53Jnl4qb5jPDHk/CxucHx6bCl5q6ouG2Neu6LPwbE+leSJsW8bAAA2rE3r6PtjSf5Gkmeq6jdH7eeTfDbJg1V1XZKXk1yTJN39bFU9mOS5LJ5MckN3vzP6XZ/k3iRnJHl0vJJFiP9cVe3J4gr2jnXMFwAAjos1h+zu/s9Zfc90klx+mD63JLlllfruJBevUv9ORkgHAICThV98BACAyYRsAACYbD17suF9aduNv3qip8Ax9q3PfvJETwGAk5wr2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTCdkAADCZkA0AAJMJ2QAAMJmQDQAAkwnZAAAwmZANAACTbTrREwDYaLbd+KsnegocB9/67CdP9BSAU5gr2QAAMJmQDQAAkwnZAAAw2UkRsqvqyqp6oar2VNWNJ3o+AABwJBs+ZFfVaUn+ZZK/luTCJJ+uqgtP7KwAAODwToani1yaZE93/3aSVNUDSa5K8twJnRUAJzVPkXl/8BQZTpSTIWRvSfLK0ue9ST52guYCAJxE/MfU+8NG/I+pkyFk1yq1PqRB1a4ku8bH/11VLxzzWa3unCS/d4L+2hw/1vnUZ43fH6zz+4N1fh+oW0/YOv/xw504GUL23iTnLX3emuTV5QbdfVeSu47npFZTVbu7e/uJngfHlnU+9Vnj9wfr/P5gnd8fNuI6b/gbH5N8NckFVXV+VX1vkh1JHjnBcwIAgMPa8Feyu/tAVf2dJF9OclqSe7r72RM8LQAAOKwNH7KTpLv/fZJ/f6Ln8S6c8C0rHBfW+dRnjd8frPP7g3V+f9hw61zdffRWAADAu3Yy7MkGAICTipA9gZ99P3VU1XlV9R+q6vmqeraqfmbUz66qx6rqxfF+1lKfm8bav1BVV5y42fNeVNVpVfWNqvp347M1PsVU1Q9U1UNV9Vvjn+k/b51PPVX1d8ef19+sqi9U1R+1zie/qrqnql6vqm8u1d7zulbVJVX1zDh3e1Wt9mjoY0LIXic/+37KOZDk73X3n05yWZIbxnremOTx7r4gyePjc8a5HUkuSnJlkjvG3xNsfD+T5Pmlz9b41PMvkvxad/9wkj+bxXpb51NIVW1J8tNJtnf3xVk8IGFHrPOp4N4s1mjZWtb1zix+S+WC8Vo55jEjZK/f///Z9+7+gyQHf/adk1B3v9bdXx/Hb2XxL+UtWazpfaPZfUmuHsdXJXmgu9/u7peS7Mni7wk2sKramuSTSX55qWyNTyFVdWaSv5Tk7iTp7j/o7v8Z63wq2pTkjKralOQDWfyWhnU+yXX3V5LsX1F+T+taVecmObO7n+zFTYj3L/U55oTs9VvtZ9+3nKC5MFFVbUvyI0meSvKR7n4tWQTxJB8ezaz/yemfJ/m5JH+4VLPGp5Y/kWRfkn81tgX9clV9X6zzKaW7fyfJLyV5OclrSd7s7l+PdT5Vvdd13TKOV9aPCyF7/Y76s++cfKrq+5P86yQ/293/60hNV6lZ/w2sqn4iyevd/bV322WVmjXe+DYl+dEkd3b3jyT5/Yz/tXwY1vkkNPbkXpXk/CQ/mOT7quozR+qySs06n/wOt64ndL2F7PU76s++c3Kpqu/JImB/vru/NMrfHv/bKeP99VG3/iefH0vyk1X1rSy2d/14Vf1KrPGpZm+Svd391Pj8UBah2zqfWv5Kkpe6e193/98kX0ryF2KdT1XvdV33juOV9eNCyF4/P/t+Chl3Hd+d5Pnu/mdLpx5JsnMc70zy8FJ9R1WdXlXnZ3FTxdPHa768d919U3dv7e5tWfzz+kR3fybW+JTS3b+b5JWq+lOjdHmS52KdTzUvJ7msqj4w/vy+PIt7aazzqek9revYUvJWVV02/v64dqnPMXdS/OLjRuZn3085P5bkbyR5pqp+c9R+PslnkzxYVddl8Yf6NUnS3c9W1YNZ/Mv7QJIbuvud4z5rZrDGp56fSvL5cQHkt5P8zSwuLlnnU0R3P1VVDyX5ehbr9o0sfvnv+2OdT2pV9YUkH09yTlXtTXJz1vbn9PVZPKnkjCSPjtfx+Q5+8REAAOayXQQAACYTsgEAYDIhGwAAJhOyAQBgMiEbAAAmE7IBAGAyIRsAACYTsgEAYLL/BwtpS6zH1RgUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(X_train_df['X'].str.split().apply(len), range=[0, 1000], bins= 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2: Tokenization Process\n",
    "\n",
    "The tokenization process was peformed above. The overall goal of the tokenization process is to determine the prioritized list of words in each row or document of text. Tokenization reduces the amount of data needed to input into the model through steps determined by the user as needed. These steps can include:\n",
    "\n",
    " - Remove unusual characters and punctuation such as !@#$%^&*()\n",
    " - Perform stemming and/or lemmatization by removing endings to root words such as '..ly', '..ing', etc. Stemming uses the stem of the word, while lemmatization uses the context in which the word is being used. \n",
    " - Remove stopwords which are commonly used words in a language such as \"a, the, is, are, etc\". This was performed above using Spacys built in stopwords list.\n",
    "\n",
    "The tokenization process may be modified or skipped based on the need of the overall goal of the analysis.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3: Padding Process\n",
    "\n",
    "To begin the padding process, the tokens produced were transformed into their integer values found in the dictionary produced using Keras's ```fit_on_texts()``` function. This dictionary was partially show above by showing the first 20 items in the function's word_index dictionary.\n",
    "\n",
    "The ```text_to_sequences()``` functions peforms transformation by producing an array of integers for each row corresponding with each word in the dictionary. However, the lengths of the arrays vary because the number of tokens in each row vary. In order to fit into the model the arrays shape must be consistant. \n",
    "\n",
    "The padding process is used to fix this issue. The dictionary value \"0\" is saved for padding values. As determined above the maximum length for each sequence is 400. Using Kera's ```pad_sequence()``` function and the hyperparameter ```padding=post``` the integer arrays are padded with 0's until they are length 400. Using post padding ensures tokens are not cut from the data. For arrays with greater than 400 values, these arrays are truncated at lengths of 400.\n",
    "\n",
    "A single padded sequence is shown below. We can verify the shape of the matrix array by using ```.shape``` to verify the length of 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change texts into sequence of indexes\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the numerical matric to a max length of 400\n",
    "X_train = pad_sequences(X_train, maxlen=400, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen= 400, padding= 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2    24   350    16  1039  1408 18645  8983  1297     2    16     2\n",
      "   129   448     2   113     6  5023   403     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "#Provide code for single padded sequence from training set\n",
    "print(X_train[8,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   56   765 19133    91   215     3    10   176  3552     3   711 11651\n",
      "  3235   282  5247     3     3   269   511  1107   180   517  3552   732\n",
      "  6740   457    12  5595   656  3608  2733   282     6   389   942    64\n",
      "   176   942    91     9   233   502   923   942    15   174   643   484\n",
      "   176  1105   280    92    88  1443   765    77     4   109   131    25\n",
      "    17   156  7274  8586   245     7   233   787   363   201   788   211\n",
      "   429    17   203    48   693  1967    16   203    48   215     3   158\n",
      "   787  2973    10   942   211   656    48    51     6  1295   923 17277\n",
      "   189  1067   121   656  1067    48    48   119    43  1087  1515    18\n",
      "   949     1   626   656    48  1515   756    17     3    43   656    48\n",
      "   501   788     5   121  1095   627   942   541   446    17    96   208\n",
      "  5422   208    18  1543  1558     2   116   770   877   127   131    61\n",
      "    18    17    40   241    61   502  3593   189    75   244    32    12\n",
      "    50    61   628   205  3349   211    19  1059  3524   108  4415    50\n",
      "    61     9   175   122    61    36     1   402     3  3593   583  4408\n",
      "  1678   359   208   942     2   208    61  4426   189  2700   359   208\n",
      "   942    48   208    61  2009    45     2    19   547  2096   501 28610\n",
      "  1095   942  2297    19   127    61   656   877    48    10  1352   942\n",
      "   222   923   185  1300  3368    19    61   190   208  1690   208    10\n",
      "   203     5  3227  3593    61  1942 38440   233   687  7513    50     7\n",
      "   158    33   108    15  1782    61   774   233    43   571   586  1277\n",
      "    14    51  1321   215  5247     3     2    19    14    62   254  4306\n",
      "   502  2730   254  4790  1035   682   146   215  5247     3  2841  1111\n",
      "   682  3093  2969  4936    59     2    19    45    19    44  4536  2574\n",
      "    17   156   345    17   203    48  2812  8358   146    96   495   215\n",
      "  5247     3     9   181    61   711    93  6617   402    12   297    14\n",
      "  1888   363   282  3552   511  4687   188   156  3474   266  6740   208\n",
      "   171   743   208   208   171  3151   208   710   198   189     3   338\n",
      "   537     9  2021  2135    34    10   110   817    12   149   942   109\n",
      "   423   565   429  1095    19   279   423    50   162    92   226   541\n",
      "  1473  6358   205   628    50    12  1906  2697   160     5  5096  1095\n",
      "   695  1168   490     2    19    10    61   233     2    26    59  9921\n",
      "  2021  2135    57     3  2841    26     5   449   265   315   411   502\n",
      "     9     6   280  1092]\n"
     ]
    }
   ],
   "source": [
    "#Provide code for single padded sequence from test set\n",
    "print(X_test[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 1,\n",
       " 'i': 2,\n",
       " 'game': 3,\n",
       " 'play': 4,\n",
       " 'like': 5,\n",
       " 'good': 6,\n",
       " 'time': 7,\n",
       " 'great': 8,\n",
       " 'fun': 9,\n",
       " 'use': 10,\n",
       " 'character': 11,\n",
       " 'new': 12,\n",
       " 'thing': 13,\n",
       " 'graphic': 14,\n",
       " 'look': 15,\n",
       " 'buy': 16,\n",
       " 'story': 17,\n",
       " 'level': 18,\n",
       " 'find': 19,\n",
       " 'way': 20}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output first 20 results of work_index dictionary\n",
    "dict(list(word_index.items())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185388, 400)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of X_train matrix\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46348, 400)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of X_test matrix\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the max input_len for the model\n",
    "review_len = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4: Sentiment Categories\n",
    "\n",
    "There are 5 categories that will be used to determine the sentiment of the model and predictions. These catergories are the stars given for each product review with 1 being the most negative to 5 being the most positive. However, when one hot encoding is performed 6 categories will be used because the values of all 0s is also encoded. No issues should arise because no 0s or missing values were found when checking the target data. \n",
    "\n",
    "The activation function 'softmax' will be used in the final dense layer of the model network. Softmax performs calculations to determine the most probable sentiment category for the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B5: Data Analysis Preparation Steps\n",
    "\n",
    "The steps used to prepare the data for analysis are as follows:\n",
    "\n",
    "1. Read the data into a usable format for processing. This was performed above by reading the Amazon .json file and transforming it into a DataFrame\n",
    "2. Peform data cleaning and exploration by checking for duplicates, missing data, abnormal inputs, etc. and imputing or removing as necessary.\n",
    "3. Check for abnormal character and replace or remove as necessary. The function loop above performed this automatically using various Regex functions.\n",
    "4. Split the data into an 80/20 split. The 80% allocated data will be used to train the model and the remaining 20% is used to test the model.\n",
    "5. Tokenize each row of reviews in the training set. In the tokenization process, lemmatization is also performed.\n",
    "6. Identify the vocabulary length of the training data in order to determine a word embedding length.\n",
    "7. Retrieve the word_index of the training data.\n",
    "8. Perform numerical sequencing of both the training and test data.\n",
    "9. Perform selected exploration to determine a maximun length of vectors to use in the padding sequence. Use the determine length to pad each sequence.\n",
    "10. Transform the training and test sets into NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B6: Copy of Prepared Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.DataFrame(X_train)\n",
    "df_x_test = pd.DataFrame(X_test)\n",
    "df_y_train = pd.DataFrame(y_train)\n",
    "df_y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train.iloc[0:1000].to_csv(\"C:/Users/holtb/Data/WGU Datasets/df_xtrain_sample.csv\")\n",
    "df_x_test.iloc[0:1000,].to_csv(\"C:/Users/holtb/Data/WGU Datasets/df_xtest_sample.csv\")\n",
    "df_y_train.iloc[0:1000,].to_csv(\"C:/Users/holtb/Data/WGU Datasets/df_ytrain_sample.csv\")\n",
    "df_y_test.iloc[0:1000,].to_csv(\"C:/Users/holtb/Data/WGU Datasets/df_ytest_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1: Model Output Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"emb_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Embedding (Embedding)        (None, 400, 50)           7389100   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 6)                 156       \n",
      "=================================================================\n",
      "Total params: 7,400,681\n",
      "Trainable params: 7,400,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "# Create a model with embeddings\n",
    "model = Sequential(name=\"emb_model\")\n",
    "#Input layer\n",
    "model.add(Embedding(input_dim=vocabulary_size+1, output_dim=50, input_length=review_len, \n",
    "                    trainable=True, name = \"Embedding\"))\n",
    "#\n",
    "model.add(GlobalMaxPool1D())\n",
    "# GRU layer with 64\n",
    "model.add(Dense(100, activation='relu', name = 'Dense_1'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50, activation='relu', name = 'Dense_2'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(25, activation='relu', name = 'Dense_3'))\n",
    "# Output layer\n",
    "model.add(Dense(6, activation='softmax', name = 'Output'))\n",
    "# Compile model with optimizer and loss functions\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Print the summaries of the model with embeddings\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4346/4346 [==============================] - 203s 46ms/step - loss: 1.1069 - accuracy: 0.5498 - val_loss: 1.0015 - val_accuracy: 0.5829\n",
      "Epoch 2/20\n",
      "4346/4346 [==============================] - 203s 47ms/step - loss: 0.9971 - accuracy: 0.5879 - val_loss: 1.0089 - val_accuracy: 0.5864\n",
      "Epoch 3/20\n",
      "4346/4346 [==============================] - 204s 47ms/step - loss: 0.9550 - accuracy: 0.6039 - val_loss: 0.9908 - val_accuracy: 0.5949\n",
      "Epoch 4/20\n",
      "4346/4346 [==============================] - 223s 51ms/step - loss: 0.9212 - accuracy: 0.6170 - val_loss: 1.0019 - val_accuracy: 0.5859\n",
      "Epoch 5/20\n",
      "4346/4346 [==============================] - 235s 54ms/step - loss: 0.8929 - accuracy: 0.6298 - val_loss: 1.0145 - val_accuracy: 0.5854\n"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history_train = model.fit(X_train, y_train, validation_split = 0.25, epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449/1449 [==============================] - 2s 2ms/step - loss: 1.0180 - accuracy: 0.5844\n"
     ]
    }
   ],
   "source": [
    "history_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2: Layer Types, Numbers, and Parameters\n",
    "\n",
    "- Number of Layers: There are eight layers in the sequential model: one input embedding layer, three Dense layers, two Dropout layers, and one Dense output layer.\n",
    "\n",
    "- Type of Layers:\n",
    "    - Embedding - The embedding layer is needed to use inputs of sequence matrices (such as the one being used). Without the embedding layer, the inputs would need to be one-hot encoded. This wouldn't be feasible with large datasets as the one-hot encoding matrix would require a huge amount of memory and reduces model efficiency. Additionally, embedding groups similar words into vectors enhancing the model accuracy and efficiency.\n",
    "    - GlobalMaxPool1D - \n",
    "    - Dropout -  \n",
    "    - Dense - The dense layer is the most simple type of layer, taking in input and adjusting the weight from each input.\n",
    "\n",
    "- Total number of parameters: There are a total of 2,816,339 parameters in the model with the majority of them occurring in the embedding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3: Hyperparameter Justification\n",
    "\n",
    "### Activation functions\n",
    "The activation functions in the model are located in the Dense layers. The first Dense layers contains the relu activation which sets any negative outputs to 0. The output Dense layer contains a 'softmax' activation function. This activation function was selected to predict the most likely category output (target value) from the input. \n",
    "\n",
    "### Number of nodes per layer\n",
    "When creating the architecture for the model, the number of nodes started low and then were increased until the model began to overfit. Additionally, the number of nodes per layer was selected in a way to provide a reasonable runtime for training the model. More nodes could be selected which could improve the accuracy but would require much more time to train the model.\n",
    "\n",
    "### Loss function\n",
    "The loss function \"categorical_crossentropy\" was selected because it is a popular and appropriate loss function to choose for categorical targets.\n",
    "\n",
    "### Optimizer\n",
    "The optimizer 'adam' was selected because it is one of the most common and efficient optimizers in machine learning. The Adam optimizer has the following benifits:\n",
    "\n",
    "- Straightforward to implement.\n",
    "- Computationally efficient.\n",
    "- Little memory requirements.\n",
    "- Invariant to diagonal rescale of the gradients.\n",
    "- Well suited for problems that are large in terms of data and/or parameters.\n",
    "- Appropriate for non-stationary objectives.\n",
    "- Appropriate for problems with very noisy/or sparse gradients.\n",
    "- Hyper-parameters have intuitive interpretation and typically require little tuning.\n",
    "\n",
    "(Brownlee, 2021)\n",
    "\n",
    "Additionally, the learning rate for the optimizer was set to .001. This assists the optimizer with locating the optimal derivative values without \"skipping\" them while training.\n",
    "\n",
    "### Stopping criteria\n",
    "The validation loss was selected to be used as the stopping criteria. If no significant improvements were made in the loss then the model stops training. This helps prevent the model from overfitting because, even if the training loss continues to improve, it won't make a difference unless the validation loss improves as well. \n",
    "\n",
    "### Evaluation metric\n",
    "\n",
    "The evaluation metric selected as the 'accuracy' metric. This metric allows the model to be compared to other models by evaluating the probability of it predicting the correct category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Model Evaluation\n",
    "\n",
    "## D1: Stopping Criteria Impact\n",
    "\n",
    "The stopping criteria defined in the ```model.fit()``` function allows the model to continue training until performance in the selected criteria declines. This allows the model to train multiple epochs without needing to worry about wasting time or resources continuing the training if performance doesn't improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D2: Training Process Visualization\n",
    "\n",
    "Below is a plot which visualizes the accuracy and the validation accuracy for each epoch trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_train.history['accuracy'])\n",
    "plt.plot(history_train.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_train.history['loss'])\n",
    "plt.plot(history_train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D3: Model Fitness Assessment\n",
    "\n",
    "The evaluation metric used to evaluate how well the model can classify the categories was 'accuracy'. The model's accuracy outcome was approximately 62% for training, 58% for validation, and 58% for the testing accuracy. The model ran for 5 epochs and, while the training data accuracy and loss improved, the validation accuracy and loss hover around the same levels. This suggest the model may need more data to train, added complexity, or more focused target categories. \n",
    "\n",
    "To address overfitting, dropout layers were added into the model. The dropout layers sets a percentage of the nodes (set to 0.5 in the model) to be randomly set to zero. This forces the model to retrain them on each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D4: Predictive Accuracy\n",
    "\n",
    "As shown below in the classification report, the model had the most success predicting five-star rating reviews at a 73% accuracy. The second highest was the one-star review ratings at only 44%. The model had an accuracy of 58% over all categories of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform y_test to DataFrame\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        5\n",
      "1        4\n",
      "2        5\n",
      "3        3\n",
      "4        5\n",
      "        ..\n",
      "46343    4\n",
      "46344    4\n",
      "46345    4\n",
      "46346    5\n",
      "46347    5\n",
      "Length: 46348, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of decoder\n",
    "df_transform = pd.DataFrame({0:[0,0,0,0,0,0], 1:[0,1,0,0,0,0], 2:[0,0,1,0,0,0], 3:[0,0,0,1,0,0], 4:[0,0,0,0,1,0], 5:[0,0,0,0,0,1]})\n",
    "\n",
    "# Create one hot decoder\n",
    "def decode(row):\n",
    "    for c in y_test_df.columns:\n",
    "        if row[c]==1:\n",
    "            return c\n",
    "\n",
    "# Apply decoder to y_test_df\n",
    "y_test_cat = y_test_df.apply(decode,axis=1)\n",
    "print(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predications with X_test\n",
    "y_pred = model.predict(X_test)\n",
    "predicted_categories = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.59      0.51      3044\n",
      "           2       0.31      0.07      0.12      2721\n",
      "           3       0.35      0.35      0.35      5556\n",
      "           4       0.42      0.38      0.40     11071\n",
      "           5       0.73      0.79      0.76     23956\n",
      "\n",
      "    accuracy                           0.58     46348\n",
      "   macro avg       0.45      0.44      0.43     46348\n",
      "weighted avg       0.56      0.58      0.57     46348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform datatypes\n",
    "y_pred = y_pred.astype(int)\n",
    "y_test_arr = y_test_cat.to_numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test_arr, predicted_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Summary and Recommendations\n",
    "\n",
    "## E. Code used to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Embedding_input with unsupported characters which will be renamed to embedding_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/holtb/Documents/GitHub/D213_Advanced_Data_Analytics/model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/holtb/Documents/GitHub/D213_Advanced_Data_Analytics/model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/holtb/Documents/GitHub/D213_Advanced_Data_Analytics/model_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Functionality of the Neural Network and Network Architecture Impact\n",
    "\n",
    "231,780 customer reviews were input into the model to predict each reviewer's rating based on the text of the review. The neural network took the tokenized reviews and input each review while attempting to \"learn\" which words/word combinations most accurately predicted the rating. \n",
    "\n",
    "The model begins by using embedding to create word vectors. These vectors are trained by predicting what words are most like each other. This reduces the training time of the model but may create accuracy issues due to the loss of context meaning, misspellings, etc. The data continues through the Dense layer nodes adjusting weights as it backpropegated through the model. Once the model creates the weights it deems to most accurately predict the outcomes, the model is created. Test data can then be tested against the training data to check for model accuracy.\n",
    "\n",
    "While the model didn't perform well, some things that could be improved to create a better-performing model. First, the target categorical data is pretty broadly defined. When reviewing the written reviews, many of the same words and language in one- or two-star reviews and four- or five-star reviews are similar or the same. This may make it difficult for the model to distinguish between these reviews and make accurate predictions. If the categorical variables were combined into negative (1 & 2 stars), neutral(3 stars), and positive (4 & 5 stars) this could make the model much more accurate. Additionally, due to time constraints and resources, a more complex model can be created. While performing experimentation to select a model to use, a model with LSTM and GPU layers was created that had 70% accuracy in the training set and 60% validation and testing set accuracy. While this model was more accurate, it was overfitted and needed adjustments. However, each epoch took 45 minutes to an hour to run requiring much more time than available. \n",
    "\n",
    "## G. Course of Action\n",
    "\n",
    "The purpose of the natural language processing model that was created was to identify customer sentiment on a 5-star rating model. The model can assist in identifying brand awareness and create real-time awareness of sentiment analysis of specific products to make faster and more reliable changes to prodcuts.  While the model currently underperforms as it is, if more resources were provide, I have no doubt that a much more accurate model can be obtained. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Brownlee, J. (2021, January 12). Gentle introduction to the adam optimization algorithm for deep learning. Machine Learning Mastery. Retrieved March 21, 2022, from https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ \n",
    "\n",
    "Introducing tensorflow feature columns. Google Developers Blog. (n.d.). Retrieved March 21, 2022, from https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html \n",
    "\n",
    "https://proceedings.neurips.cc/paper/2018/file/b534ba68236ba543ae44b22bd110a1d6-Paper.pdf\n",
    "\n",
    "Ups and downs: Modeling the visual evolution of fashion ... (n.d.). Retrieved March 22, 2022, from https://cseweb.ucsd.edu/~jmcauley/pdfs/www16a.pdf \n",
    "\n",
    "Yin, Z., & Shin, Y. (n.d.). On the dimensionality of word embedding - list of proceedings. Retrieved March 22, 2022, from https://proceedings.neurips.cc/paper/2018/file/b534ba68236ba543ae44b22bd110a1d6-Paper.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Party Code\n",
    "\n",
    "Becker, D. \"Introduction to Deep Learning in Python\" [MOOC]. Datacamp. https://app.datacamp.com/learn/courses/introduction-to-deep-learning-in-python\n",
    "\n",
    "Cecchini, D. \"Recurrent Neural Networks for Language Modeling in Python\" [MOOC]. Datacamp. https://app.datacamp.com/learn/courses/recurrent-neural-networks-for-language-modeling-in-python\n",
    "\n",
    "Chollet, F., & others. (2015). Keras. GitHub. Retrieved from https://github.com/fchollet/keras\n",
    "\n",
    "Harris, C.R., Millman, K.J., van der Walt, S.J. et al. Array programming with NumPy. Nature 585, 357–362 (2020). DOI: 0.1038/s41586-020-2649-2. (Publisher link)\n",
    "\n",
    "Honnibal, M., & Montani, I. (2017). spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.\n",
    "\n",
    "Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,\n",
    "Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis,\n",
    "Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,\n",
    "Andrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz, Yangqing Jia,\n",
    "Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Mike Schuster,\n",
    "Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens,\n",
    "Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,\n",
    "Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,\n",
    "Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke,\n",
    "Yuan Yu, and Xiaoqiang Zheng.\n",
    "TensorFlow: Large-scale machine learning on heterogeneous systems,\n",
    "2015. Software available from tensorflow.org.\n",
    "\n",
    "J. McAuley, R. He. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering, WWW, 2016\n",
    "\n",
    "J. D. Hunter, \"Matplotlib: A 2D Graphics Environment\", Computing in Science & Engineering, vol. 9, no. 3, pp. 90-95, 2007\n",
    "\n",
    "Python Software Foundation. Python Language Reference, version 3.7. Available at http://www.python.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c0264f263aa810bac10643d1946f68226e103f84e34bf488a94ed570c9602ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('WGU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
